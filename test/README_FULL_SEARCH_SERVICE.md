# üîç Full Search Service - Thu·∫≠t To√°n T√¨m Ki·∫øm H√¨nh ·∫¢nh Multi-Modal

## üìñ T·ªïng quan

**Full Search Service** l√† m·ªôt thu·∫≠t to√°n t√¨m ki·∫øm h√¨nh ·∫£nh ti√™n ti·∫øn s·ª≠ d·ª•ng **3 ph∆∞∆°ng ph√°p k·∫øt h·ª£p**:
- üß† **CLIP** (Ng·ªØ nghƒ©a/Semantic) - 85%
- üé® **Color Histogram** (M√†u s·∫Øc) - 10%  
- üî¢ **Hash (dHash)** (C·∫•u tr√∫c) - 5%

Thu·∫≠t to√°n ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ **∆∞u ti√™n ng·ªØ nghƒ©a** gi·ªëng nh∆∞ Google Reverse Image Search, ƒë·∫∑c bi·ªát hi·ªáu qu·∫£ v·ªõi ·∫£nh m·ªù ho·∫∑c ch·∫•t l∆∞·ª£ng k√©m.

---

## üöÄ T√≠nh nƒÉng ch√≠nh

### ‚ú® **Multi-Modal Search**
- **CLIP Embedding**: Hi·ªÉu ng·ªØ nghƒ©a v√† n·ªôi dung ·∫£nh
- **Color Analysis**: So s√°nh ph√¢n b·ªë m√†u s·∫Øc (global + center crops)
- **Hash Matching**: Ph√°t hi·ªán near-duplicates v√† c·∫•u tr√∫c t∆∞∆°ng t·ª±

### üéØ **Smart Ranking System**
```
Priority 1: High CLIP Matches (similarity ‚â• 0.7)
Priority 2: Strong Hash Matches (distance ‚â§ 6)  
Priority 3: Regular Combined Score Matches
```

### üß¨ **Adaptive Quality Processing**
- T·ª± ƒë·ªông ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng ·∫£nh (m·ªù, ƒë·ªô ph√¢n gi·∫£i, ƒë·ªô t∆∞∆°ng ph·∫£n)
- ƒêi·ªÅu ch·ªânh tr·ªçng s·ªë v√† threshold d·ª±a tr√™n ch·∫•t l∆∞·ª£ng
- X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho ·∫£nh k√©m ch·∫•t l∆∞·ª£ng

### üîÑ **Robust Fallback Mechanisms**
- ANN Index fallback to full DB scan
- CLIP restriction fallback to global search
- Expansion search khi candidates √≠t

---

## üèóÔ∏è Ki·∫øn tr√∫c h·ªá th·ªëng

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Input Image   ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Quality Analysis ‚îÇ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ Param Adjustment ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                                              ‚îÇ
          ‚ñº                                              ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ CLIP Embedding  ‚îÇ    ‚îÇ Color Histogram  ‚îÇ    ‚îÇ   Hash dHash    ‚îÇ
‚îÇ   (Semantic)    ‚îÇ    ‚îÇ   (Color Dist)   ‚îÇ    ‚îÇ  (Structure)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
          ‚îÇ                       ‚îÇ                       ‚îÇ
          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ   Candidate Pool    ‚îÇ
                     ‚îÇ  (Map merging)      ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ   Score & Rank      ‚îÇ
                     ‚îÇ (3-tier priority)   ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                  ‚îÇ
                                  ‚ñº
                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                     ‚îÇ   Final Results     ‚îÇ
                     ‚îÇ    (Top K)          ‚îÇ
                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîß API Reference

### **searchFullWithBuffer(buffer, query)**
T√¨m ki·∫øm t·ª´ ·∫£nh upload (Buffer)

```javascript
const result = await searchFullWithBuffer(imageBuffer, {
    topK: 20,                    // S·ªë k·∫øt qu·∫£ tr·∫£ v·ªÅ
    minSim: 0.15,               // Ng∆∞·ª°ng CLIP similarity t·ªëi thi·ªÉu
    clipWeight: 0.85,           // Tr·ªçng s·ªë CLIP (0-1)
    colorWeight: 0.10,          // Tr·ªçng s·ªë Color (0-1)  
    hashWeight: 0.05,           // Tr·ªçng s·ªë Hash (0-1)
    restrictToClip: true,       // Ch·ªâ t√≠nh color/hash tr√™n CLIP candidates
    colorVariant: "multi",      // "multi" | "global"
    combine: "weighted"         // "weighted" | "lexi"
});
```

### **searchFullByImageId(imageId, query)**
T√¨m ki·∫øm t·ª´ ·∫£nh c√≥ s·∫µn trong DB

```javascript
const result = await searchFullByImageId(123, {
    topK: 20,
    minSim: 0.15
    // ... c√°c tham s·ªë t∆∞∆°ng t·ª±
});
```

---

## üìä C·∫•u tr√∫c k·∫øt qu·∫£

```javascript
{
    results: [
        {
            imageId: 456,
            url: "/uploads/images/cat.jpg",
            filename: "cat.jpg", 
            original_name: "my_cat_photo.jpg",
            title: "Cute cat",
            description: "A fluffy cat",
            
            // Scores
            clipSimilarity: 0.845,      // [0-1] cao = t·ªët
            colorDistance: 0.234,       // [0-2] th·∫•p = t·ªët  
            hashDistance: 12,           // [0-64] th·∫•p = t·ªët
            score: 0.156,              // Combined score (th·∫•p = t·ªët)
            
            // Internal (for debugging)
            _clipDist: 0.155,
            _colorDist: 0.117, 
            _hashDist: 0.1875
        }
    ],
    info: {
        topK: 20,
        weights: { clipWeight: 0.85, colorWeight: 0.10, hashWeight: 0.05 },
        minSim: 0.15,
        qualityAnalysis: {
            qualityScore: 0.8,
            isBlurry: false,
            variance: 245.6
        }
    }
}
```

---

## ‚öôÔ∏è V√≤ng ƒë·ªùi x·ª≠ l√Ω chi ti·∫øt

### **Phase 1: Pre-processing** ‚è±Ô∏è ~50-100ms
```javascript
// 1. Ph√¢n t√≠ch ch·∫•t l∆∞·ª£ng ·∫£nh
const quality = await analyzeImageQuality(buffer);
// ‚Üí ƒê√°nh gi√°: variance, resolution, blur detection

// 2. ƒêi·ªÅu ch·ªânh tham s·ªë adaptive  
const adjusted = adjustSearchParams(query, quality);
// ‚Üí ·∫¢nh m·ªù: tƒÉng CLIP weight, gi·∫£m minSim

// 3. Normalize options
const opts = buildOptions(adjusted);
// ‚Üí Chu·∫©n h√≥a weights, set candidate counts
```

### **Phase 2: CLIP Processing** ‚è±Ô∏è ~200-500ms
```javascript
// 1. Compute embedding
const qVec = await clip.computeClipEmbedding(buffer);
// ‚Üí Vector 512-dim (CLIP-ViT-Base-Patch32)

// 2. Search candidates
if (ann.isAvailable()) {
    // Fast ANN search (~50ms)
    results = await ann.annSearch(qVec, opts.clipCand);
} else {
    // Full DB scan (~300-800ms)
    // Cosine similarity v·ªõi t·∫•t c·∫£ embeddings
}

// 3. Filter by minSim threshold
candidates = results.filter(r => r.similarity >= opts.minSim);
```

### **Phase 3: Color Processing** ‚è±Ô∏è ~100-300ms
```javascript
// 1. Compute query histograms
const globalHist = await colors.computeColorHistogram(buffer);
const centerHists = await computeCenterColorHistograms(buffer, [0.8, 0.6, 0.4]);

// 2. Compare v·ªõi candidates
for (candidate of colorCandidates) {
    // Chi-square distance cho m·ªói histogram
    let bestDist = Infinity;
    for (qHist of queryHistograms) {
        const dist = colors.chiSquareDistance(qHist.vector, candidate.hist);
        if (dist < bestDist) bestDist = dist;
    }
}
```

### **Phase 4: Hash Processing** ‚è±Ô∏è ~80-200ms  
```javascript
// 1. Compute multiple query hashes
const globalHash = await hash.computeDHashHex(buffer);          // 1 hash
const tileHashes = await hash.computeTileDHashes(buffer, [3,4,5]); // 9+16+25 = 50 hashes  
const overlapHashes = await hash.computeOverlappingTileDHashes(buffer); // ~25 hashes

// 2. Compare v·ªõi DB hashes
for (candidate of hashCandidates) {
    let bestDist = Infinity;
    for (qHash of queryHashes) {
        const dist = hash.hammingDistanceHex(qHash, candidate.hash);
        if (dist < bestDist) bestDist = dist;
        if (bestDist === 0) break; // Perfect match
    }
}
```

### **Phase 5: Scoring & Ranking** ‚è±Ô∏è ~10-30ms
```javascript
// 1. Calculate combined scores
const score = weights.clipWeight * clipDist + 
              weights.colorWeight * colorNorm + 
              weights.hashWeight * hashNorm;

// 2. Apply CLIP boost
if (clipSimilarity >= 0.7) {
    const boost = (clipSimilarity - 0.7) * 0.5;
    score = score * (1 - boost); // Gi·∫£m score = rank cao h∆°n
}

// 3. 3-tier ranking
const highClip = candidates.filter(x => x.clipSimilarity >= 0.7)
    .sort((a,b) => b.clipSimilarity - a.clipSimilarity);

const strongHash = candidates.filter(x => x.hashDistance <= 6 && x.clipSimilarity < 0.7)
    .sort((a,b) => a.hashDistance - b.hashDistance);
    
const regular = remaining.sort((a,b) => a.score - b.score);

// 4. Final merge
return [...highClip, ...strongHash, ...regular].slice(0, topK);
```

---

## üî¨ Fallback Mechanisms

### **1. ANN Fallback**
```javascript
if (ann.isAvailable()) {
    results = await ann.annSearch(qVec, clipCand);
} else {
    // Fallback: Full database scan
    results = await fullEmbeddingScan(qVec);
}
```

### **2. Restriction Fallback**  
```javascript
if (opts.restrictToClip && opts.ensureColorFallback) {
    // Th√™m top color matches t·ª´ to√†n DB
    const fallback = await colorDistancesForCandidates(buffer, null);
    candidates.merge(fallback.slice(0, colorFallback));
}
```

### **3. Low Candidates Expansion**
```javascript
if (clipIdSet.size < 10) {
    console.log("Low CLIP candidates, expanding search");
    const expanded = await colorDistancesForCandidates(buffer, null);
    candidates.merge(expanded.slice(0, 50));
}
```

---

## üìà Performance Metrics

### **Timing Breakdown**
| Phase | Fast Setup | Average | Heavy Load |
|-------|------------|---------|------------|
| Quality Analysis | 20ms | 50ms | 100ms |
| CLIP Processing | 150ms | 300ms | 800ms |
| Color Processing | 80ms | 150ms | 400ms |
| Hash Processing | 60ms | 120ms | 250ms |
| Scoring & Ranking | 5ms | 15ms | 40ms |
| **Total** | **315ms** | **635ms** | **1590ms** |

### **Memory Usage**
- CLIP candidates: ~150 objects √ó 200B = 30KB
- Color candidates: ~80 objects √ó 150B = 12KB  
- Hash candidates: ~80 objects √ó 100B = 8KB
- **Total candidates pool**: ~50KB

### **Database Queries**
```sql
-- CLIP embeddings (if no ANN)
SELECT e.image_id, e.embedding, i.filename, i.title, i.description 
FROM image_embeddings e JOIN images i ON i.id = e.image_id 
WHERE e.model = ?

-- Color histograms (restricted)
SELECT ic.image_id, ic.variant, ic.histogram, i.filename
FROM image_colors ic JOIN images i ON i.id = ic.image_id  
WHERE ic.image_id IN (?, ?, ?, ...)

-- Hash signatures (restricted)
SELECT ih.image_id, ih.tile_index, ih.hash, i.filename
FROM image_hashes ih JOIN images i ON i.id = ih.image_id
WHERE ih.image_id IN (?, ?, ?, ...)
```

---

## üéõÔ∏è Tuning Parameters

### **Cho ·∫£nh ch·∫•t l∆∞·ª£ng cao**
```javascript
{
    clipWeight: 0.8,
    colorWeight: 0.15, 
    hashWeight: 0.05,
    minSim: 0.18,
    topK: 20
}
```

### **Cho ·∫£nh m·ªù/ch·∫•t l∆∞·ª£ng k√©m**
```javascript
{
    clipWeight: 0.9,     // TƒÉng cao ƒë·ªÉ ∆∞u ti√™n ng·ªØ nghƒ©a
    colorWeight: 0.05,   // Gi·∫£m v√¨ m√†u c√≥ th·ªÉ kh√¥ng ch√≠nh x√°c
    hashWeight: 0.05,
    minSim: 0.12,        // Gi·∫£m threshold
    topK: 30             // L·∫•y nhi·ªÅu k·∫øt qu·∫£ h∆°n
}
```

### **Cho exact duplicate detection**
```javascript
{
    clipWeight: 0.3,
    colorWeight: 0.2,
    hashWeight: 0.5,     // TƒÉng hash ƒë·ªÉ b·∫Øt duplicates
    hashStrongThreshold: 3,
    minSim: 0.1
}
```

---

## üêõ Debugging & Monitoring

### **Console Logs**
```
Image quality analysis: { qualityScore: 0.8, isBlurry: false }
CLIP embedding computed successfully, vector length: 512
CLIP candidates found: 45
Top 3 CLIP candidates: [...]
Color candidates found: 32
Color fallback candidates: 15
Hash candidates found: 28
Hash fallback candidates: 12
Final search results summary:
- Total candidates processed: 67
- High CLIP matches (>= 0.7): 3
- Strong hash matches: 1  
- Regular matches: 63
- Returned top 20 results
```

### **Error Handling**
```javascript
try {
    const clipRes = await clipCandidatesFromVector(qVec, opts);
} catch (e) {
    console.error("CLIP search error:", e);
    // Continue v·ªõi color/hash search
}
```

---

## üîß Configuration

### **Environment Variables**
```bash
CLIP_MODEL_ID=Xenova/clip-vit-base-patch32
TRANSFORMERS_CACHE=./cache
```

### **Database Schema**
```sql
-- Images table
CREATE TABLE images (
    id INT PRIMARY KEY,
    filename VARCHAR(255),
    file_path VARCHAR(512),
    title VARCHAR(255),
    description TEXT
);

-- CLIP embeddings
CREATE TABLE image_embeddings (
    image_id INT,
    model VARCHAR(100),
    dim INT,
    embedding JSON,
    INDEX(image_id, model)
);

-- Color histograms  
CREATE TABLE image_colors (
    image_id INT,
    variant VARCHAR(50), -- 'global', 'center_80', etc.
    histogram JSON,
    INDEX(image_id)
);

-- Hash signatures
CREATE TABLE image_hashes (
    image_id INT, 
    tile_index INT,      -- -1 for global, 0+ for tiles
    grid INT,            -- 3, 4, 5 for tile size
    hash VARCHAR(64),    -- hex string
    stride FLOAT,        -- for overlapping tiles
    INDEX(image_id)
);
```

---

## üìù Examples

### **Basic Search**
```javascript
const fs = require('fs');
const { searchFullWithBuffer } = require('./services/fullSearchService');

const imageBuffer = fs.readFileSync('query_image.jpg');
const results = await searchFullWithBuffer(imageBuffer, {
    topK: 10
});

console.log(`Found ${results.results.length} similar images`);
results.results.forEach((img, i) => {
    console.log(`${i+1}. ${img.filename} - CLIP: ${img.clipSimilarity}`);
});
```

### **Advanced Search v·ªõi custom weights**
```javascript
const results = await searchFullWithBuffer(imageBuffer, {
    topK: 20,
    clipWeight: 0.9,
    colorWeight: 0.05, 
    hashWeight: 0.05,
    minSim: 0.1,
    restrictToClip: false,  // Search to√†n b·ªô DB
    colorVariant: "global"  // Ch·ªâ d√πng global histogram
});
```

### **Search by existing image ID**
```javascript
const results = await searchFullByImageId(123, {
    topK: 15,
    minSim: 0.2
});
```

---

## üö® Troubleshooting

### **V·∫•n ƒë·ªÅ ph·ªï bi·∫øn**

**1. CLIP search ch·∫≠m**
```javascript
// Ki·ªÉm tra ANN index
if (!ann.isAvailable()) {
    console.log("ANN index not available, using full scan");
    // Rebuild ANN index
}
```

**2. K·∫øt qu·∫£ kh√¥ng relevant**
```javascript
// Ki·ªÉm tra tr·ªçng s·ªë
console.log("Current weights:", opts.weights);
// ƒêi·ªÅu ch·ªânh minSim
console.log("Current minSim:", opts.minSim);
```

**3. Memory issues**
```javascript
// Gi·∫£m candidate counts
const opts = buildOptions({
    ...query,
    clipCand: 50,  // Thay v√¨ 150
    colorCand: 30, // Thay v√¨ 80
    hashCand: 30   // Thay v√¨ 80
});
```

**4. Sharp module errors**
```bash
npm install --include=optional sharp
# ho·∫∑c
npm install --os=win32 --cpu=x64 sharp
```

---

## üìö References

- **CLIP Paper**: [Learning Transferable Visual Representations](https://arxiv.org/abs/2103.00020)
- **Perceptual Hashing**: [dHash Algorithm](http://www.hackerfactor.com/blog/index.php?/archives/529-Kind-of-Like-That.html)  
- **Color Histograms**: [Chi-square distance](https://en.wikipedia.org/wiki/Chi-squared_test)
- **ANN Search**: [Approximate Nearest Neighbors](https://en.wikipedia.org/wiki/Nearest_neighbor_search#Approximate_nearest_neighbor)

---

## üë• Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Made with ‚ù§Ô∏è for intelligent image search**
