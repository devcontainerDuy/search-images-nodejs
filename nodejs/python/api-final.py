from flask import Flask, request, jsonify
import torch
import clip
from PIL import Image
import io
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
import logging
import json
from flask_cors import CORS
import cv2
from torchvision import transforms
import time
from concurrent.futures import ThreadPoolExecutor
from functools import lru_cache

app = Flask(__name__)
CORS(app)  # Cho phÃ©p Cross-Origin requests
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Cáº¥u hÃ¬nh
device = "cuda" if torch.cuda.is_available() else "cpu"
logging.info(f"Sá»­ dá»¥ng thiáº¿t bá»‹: {device}")

# Thá»­ táº£i model lá»›n hÆ¡n náº¿u cÃ³ GPU, náº¿u khÃ´ng thÃ¬ dÃ¹ng model nhá»
if device == "cuda":
    try:
        model, preprocess = clip.load("ViT-L/14", device=device)
        model_name = "ViT-L/14"
        logging.info("ÄÃ£ táº£i mÃ´ hÃ¬nh CLIP ViT-L/14")
    except:
        model, preprocess = clip.load("ViT-B/32", device=device)
        model_name = "ViT-B/32"
        logging.info("ÄÃ£ táº£i mÃ´ hÃ¬nh CLIP ViT-B/32")
else:
    model, preprocess = clip.load("ViT-B/32", device=device)
    model_name = "ViT-B/32"
    logging.info("ÄÃ£ táº£i mÃ´ hÃ¬nh CLIP ViT-B/32")

# ThÆ° má»¥c chá»©a áº£nh sáº£n pháº©m
product_image_folder = "../uploads/products/"
# File cache cho Ä‘áº·c trÆ°ng áº£nh
feature_file_path = f"image_features_{model_name.replace('/', '_')}.npy"
paths_file_path = "image_paths.txt"
metadata_file_path = "product_metadata.json"
augmentation_enabled = True  # CÃ³ thá»ƒ báº­t/táº¯t tÄƒng cÆ°á»ng dá»¯ liá»‡u

# Biáº¿n toÃ n cá»¥c
image_paths = []
image_features = None
product_metadata = {}
executor = ThreadPoolExecutor(max_workers=4)  # Cho xá»­ lÃ½ song song

# CÃ¡c hÃ m tÄƒng cÆ°á»ng dá»¯ liá»‡u
def apply_augmentations(img_pil):
    """Táº¡o nhiá»u phiÃªn báº£n tÄƒng cÆ°á»ng cá»§a áº£nh Ä‘áº§u vÃ o"""
    augmented_images = [img_pil]  # Bao gá»“m áº£nh gá»‘c

    # Chuyá»ƒn Ä‘á»•i sang OpenCV Ä‘á»ƒ xá»­ lÃ½
    img_cv = np.array(img_pil)
    img_cv = cv2.cvtColor(img_cv, cv2.COLOR_RGB2BGR)

    # 1. Cáº£i thiá»‡n Ä‘á»™ tÆ°Æ¡ng pháº£n
    lab = cv2.cvtColor(img_cv, cv2.COLOR_BGR2LAB)
    l, a, b = cv2.split(lab)
    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
    cl = clahe.apply(l)
    enhanced_lab = cv2.merge((cl, a, b))
    enhanced_img = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
    enhanced_pil = Image.fromarray(cv2.cvtColor(enhanced_img, cv2.COLOR_BGR2RGB))
    augmented_images.append(enhanced_pil)

    # 2. CÃ¢n báº±ng histogram toÃ n cáº§u
    img_yuv = cv2.cvtColor(img_cv, cv2.COLOR_BGR2YUV)
    img_yuv[:,:,0] = cv2.equalizeHist(img_yuv[:,:,0])
    hist_eq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2BGR)
    hist_eq_pil = Image.fromarray(cv2.cvtColor(hist_eq, cv2.COLOR_BGR2RGB))
    augmented_images.append(hist_eq_pil)

    # 3. Lá»c Gaussian nháº¹ Ä‘á»ƒ lÃ m giáº£m nhiá»…u
    blurred = cv2.GaussianBlur(img_cv, (3, 3), 0)
    blurred_pil = Image.fromarray(cv2.cvtColor(blurred, cv2.COLOR_BGR2RGB))
    augmented_images.append(blurred_pil)

    # 4. Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng - tá»‘i hÆ¡n má»™t chÃºt
    brightness = cv2.convertScaleAbs(img_cv, alpha=0.9, beta=0)
    dark_pil = Image.fromarray(cv2.cvtColor(brightness, cv2.COLOR_BGR2RGB))
    augmented_images.append(dark_pil)

    # 5. Äiá»u chá»‰nh Ä‘á»™ sÃ¡ng - sÃ¡ng hÆ¡n má»™t chÃºt
    brightness = cv2.convertScaleAbs(img_cv, alpha=1.1, beta=10)
    bright_pil = Image.fromarray(cv2.cvtColor(brightness, cv2.COLOR_BGR2RGB))
    augmented_images.append(bright_pil)

    return augmented_images

# TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« má»™t áº£nh vá»›i tÄƒng cÆ°á»ng dá»¯ liá»‡u
def extract_features_with_augmentation(img_pil):
    """TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh vá»›i tÄƒng cÆ°á»ng dá»¯ liá»‡u vÃ  tÃ­nh trung bÃ¬nh"""
    if not augmentation_enabled:
        # Náº¿u khÃ´ng báº­t tÄƒng cÆ°á»ng, chá»‰ xá»­ lÃ½ áº£nh thÆ°á»ng
        return extract_features_single(img_pil)

    # Táº¡o cÃ¡c phiÃªn báº£n áº£nh tÄƒng cÆ°á»ng
    augmented_images = apply_augmentations(img_pil)

    # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng cho má»—i phiÃªn báº£n
    all_features = []
    for aug_img in augmented_images:
        # Xá»­ lÃ½ áº£nh vá»›i CLIP
        image_tensor = preprocess(aug_img).unsqueeze(0).to(device)
        with torch.no_grad():
            feature = model.encode_image(image_tensor)
            feature = feature.cpu().numpy()
            feature /= np.linalg.norm(feature)
            all_features.append(feature)

    # TÃ­nh trung bÃ¬nh cÃ¡c vector Ä‘áº·c trÆ°ng
    mean_feature = np.mean(all_features, axis=0)
    mean_feature /= np.linalg.norm(mean_feature)  # Chuáº©n hÃ³a láº¡i

    return mean_feature

# TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« má»™t áº£nh duy nháº¥t
def extract_features_single(img_pil):
    """TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« má»™t áº£nh Ä‘Æ¡n"""
    image_tensor = preprocess(img_pil).unsqueeze(0).to(device)
    with torch.no_grad():
        feature = model.encode_image(image_tensor)
        feature = feature.cpu().numpy()
        feature /= np.linalg.norm(feature)
    return feature

# Táº£i dá»¯ liá»‡u Ä‘áº·c trÆ°ng tá»« file cache
def load_image_features():
    global image_paths, image_features, product_metadata

    if os.path.exists(feature_file_path) and os.path.exists(paths_file_path):
        logging.info(f"ğŸ”„ Äang load feature tá»« file cache: {feature_file_path}...")
        image_features = np.load(feature_file_path)
        with open(paths_file_path, 'r', encoding='utf-8') as f:
            image_paths = [line.strip() for line in f.readlines()]

        # Táº£i metadata sáº£n pháº©m náº¿u cÃ³
        if os.path.exists(metadata_file_path):
            with open(metadata_file_path, 'r', encoding='utf-8') as f:
                product_metadata = json.load(f)

        logging.info(f"âœ… ÄÃ£ load {len(image_paths)} áº£nh vÃ  Ä‘áº·c trÆ°ng.")
    else:
        logging.info("âš™ï¸ KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u sáºµn cÃ³. Äang build láº¡i...")
        build_image_database()

# Xá»­ lÃ½ áº£nh theo batch Ä‘á»ƒ tiáº¿t kiá»‡m bá»™ nhá»› vÃ  tÄƒng tá»‘c
def process_image_batch(batch_files):
    results = []
    for filename in batch_files:
        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.webp')):
            path = os.path.join(product_image_folder, filename)
            try:
                # Äá»c áº£nh
                original_image = Image.open(path).convert("RGB")

                # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vá»›i tÄƒng cÆ°á»ng dá»¯ liá»‡u
                feature = extract_features_with_augmentation(original_image)

                # LÆ°u metadata cÆ¡ báº£n
                metadata = {
                    "filename": filename,
                    "path": path,
                    "size": [original_image.width, original_image.height],
                    "format": original_image.format,
                    "created": time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(os.path.getctime(path)))
                }

                results.append((filename, feature, metadata))
            except Exception as e:
                logging.warning(f"âŒ Bá» qua {filename}: {e}")
    return results

# XÃ¢y dá»±ng cÆ¡ sá»Ÿ dá»¯ liá»‡u Ä‘áº·c trÆ°ng hÃ¬nh áº£nh
def build_image_database():
    global image_paths, image_features, product_metadata

    logging.info(f"Äang xá»­ lÃ½ áº£nh tá»« thÆ° má»¥c: {product_image_folder}")

    # Láº¥y danh sÃ¡ch táº¥t cáº£ cÃ¡c file áº£nh
    all_files = [f for f in os.listdir(product_image_folder)
                if f.lower().endswith(('.png', '.jpg', '.jpeg', '.webp'))]

    if not all_files:
        logging.error("âŒ KhÃ´ng tÃ¬m tháº¥y áº£nh há»£p lá»‡ trong thÆ° má»¥c!")
        return

    # Chia thÃ nh cÃ¡c batch Ä‘á»ƒ xá»­ lÃ½
    batch_size = 50  # Äiá»u chá»‰nh theo RAM cÃ³ sáºµn
    batches = [all_files[i:i + batch_size] for i in range(0, len(all_files), batch_size)]

    paths = []
    features = []
    metadata = {}

    processed_count = 0
    start_time = time.time()

    # Xá»­ lÃ½ tá»«ng batch
    for i, batch in enumerate(batches):
        logging.info(f"Äang xá»­ lÃ½ batch {i+1}/{len(batches)}...")

        # Xá»­ lÃ½ song song
        batch_results = list(executor.map(process_image_batch, [[f] for f in batch]))
        batch_results = [item for sublist in batch_results for item in sublist]  # Flatten

        for filename, feature, meta in batch_results:
            paths.append(filename)
            features.append(feature)
            metadata[filename] = meta

            processed_count += 1
            if processed_count % 10 == 0:
                elapsed = time.time() - start_time
                img_per_sec = processed_count / elapsed
                logging.info(f"ÄÃ£ xá»­ lÃ½ {processed_count}/{len(all_files)} áº£nh... ({img_per_sec:.2f} áº£nh/giÃ¢y)")

    if features:
        image_paths = paths
        image_features = np.vstack(features)
        product_metadata = metadata

        # LÆ°u vÃ o file Ä‘á»ƒ tÃ¡i sá»­ dá»¥ng
        np.save(feature_file_path, image_features)
        with open(paths_file_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(image_paths))
        with open(metadata_file_path, 'w', encoding='utf-8') as f:
            json.dump(product_metadata, f, ensure_ascii=False, indent=2)

        logging.info(f"âœ… Build database hoÃ n táº¥t. ÄÃ£ xá»­ lÃ½ {len(paths)} áº£nh trong {time.time() - start_time:.2f} giÃ¢y.")
    else:
        logging.error("âŒ KhÃ´ng xá»­ lÃ½ Ä‘Æ°á»£c áº£nh nÃ o!")

# Cache Ä‘áº·c trÆ°ng Ä‘á»ƒ trÃ¡nh tÃ­nh toÃ¡n láº·p láº¡i
@lru_cache(maxsize=100)
def get_feature_from_bytes_cached(image_bytes_hash):
    try:
        # Táº¡o Ä‘á»‘i tÆ°á»£ng BytesIO tá»« hash
        image_bytes = image_bytes_dict.get(image_bytes_hash)
        if image_bytes is None:
            return None

        # Äá»c áº£nh tá»« bytes
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

        # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng vá»›i tÄƒng cÆ°á»ng dá»¯ liá»‡u
        feature = extract_features_with_augmentation(image)

        return feature
    except Exception as e:
        logging.error(f"Lá»—i khi xá»­ lÃ½ áº£nh gá»­i lÃªn: {e}")
        return None

# Dictionary Ä‘á»ƒ lÆ°u trá»¯ táº¡m thá»i bytes cá»§a áº£nh
image_bytes_dict = {}

# TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh Ä‘Æ°á»£c táº£i lÃªn
def get_feature_from_bytes(image_bytes):
    # Táº¡o hash tá»« bytes cá»§a áº£nh
    image_bytes_hash = hash(image_bytes)

    # LÆ°u trá»¯ bytes vÃ o dictionary
    image_bytes_dict[image_bytes_hash] = image_bytes

    # Gá»i hÃ m cache
    return get_feature_from_bytes_cached(image_bytes_hash)

@app.route('/search', methods=['POST'])
def search():
    start_time = time.time()

    if 'image' not in request.files:
        return jsonify({"error": "No image uploaded"}), 400

    file = request.files['image']
    img_bytes = file.read()

    # Láº¥y cÃ¡c tham sá»‘ tÃ¬m kiáº¿m
    min_similarity = float(request.form.get('min_similarity', 0.65))
    top_k = int(request.form.get('top_k', 50))
    category = request.form.get('category', None)

    # TÃ¹y chá»n tÄƒng cÆ°á»ng
    use_augmentation = request.form.get('use_augmentation', 'true').lower() == 'true'
    global augmentation_enabled
    augmentation_enabled = use_augmentation

    # ThÃªm log Ä‘á»ƒ theo dÃµi
    logging.info(f"Nháº­n yÃªu cáº§u tÃ¬m kiáº¿m: min_sim={min_similarity}, top_k={top_k}, augmentation={augmentation_enabled}")

    # TrÃ­ch xuáº¥t Ä‘áº·c trÆ°ng tá»« áº£nh tÃ¬m kiáº¿m
    query_feature = get_feature_from_bytes(img_bytes)
    feature_time = time.time() - start_time
    logging.info(f"Thá»i gian trÃ­ch xuáº¥t Ä‘áº·c trÆ°ng: {feature_time:.4f}s")

    if query_feature is None or image_features is None:
        return jsonify({"error": "KhÃ´ng thá»ƒ xá»­ lÃ½ áº£nh"}), 500

    # TÃ­nh toÃ¡n Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng
    similarity_start = time.time()
    sims = cosine_similarity(query_feature, image_features)[0]
    similarity_time = time.time() - similarity_start
    logging.info(f"Thá»i gian tÃ­nh cosine similarity: {similarity_time:.4f}s")

    # Sáº¯p xáº¿p káº¿t quáº£ theo Ä‘iá»ƒm sá»‘ tá»« cao Ä‘áº¿n tháº¥p
    sorting_start = time.time()
    sorted_indices = sims.argsort()[::-1]
    sorting_time = time.time() - sorting_start

    results = []
    for idx in sorted_indices:
        # Chá»‰ láº¥y káº¿t quáº£ cÃ³ Ä‘iá»ƒm sá»‘ trÃªn ngÆ°á»¡ng
        if sims[idx] < min_similarity:
            continue

        image_name = image_paths[idx]

        # Bá» qua náº¿u cÃ³ lá»c danh má»¥c vÃ  khÃ´ng khá»›p
        if category and product_metadata.get(image_name, {}).get('category', '') != category:
            continue

        # ThÃªm káº¿t quáº£
        results.append({
            "image": image_name,
            "score": float(sims[idx]),
            "image_url": f"/uploads/products/{image_name}",
            "metadata": product_metadata.get(image_name, {})
        })

        # Dá»«ng khi Ä‘á»§ sá»‘ lÆ°á»£ng káº¿t quáº£ yÃªu cáº§u
        if len(results) >= top_k:
            break

    total_time = time.time() - start_time
    logging.info(f"TÃ¬m kiáº¿m hoÃ n táº¥t: {len(results)} káº¿t quáº£ trong {total_time:.4f}s")

    return jsonify({
        "total_results": len(results),
        "min_similarity": min_similarity,
        "results": results,
        "timing": {
            "feature_extraction": feature_time,
            "similarity_calculation": similarity_time,
            "sorting": sorting_time,
            "total": total_time
        },
        "use_augmentation": augmentation_enabled,
        "model": model_name
    })

@app.route('/rebuild', methods=['GET'])
def rebuild_database():
    build_image_database()
    return jsonify({"status": "success", "message": "ÄÃ£ xÃ¢y dá»±ng láº¡i cÆ¡ sá»Ÿ dá»¯ liá»‡u hÃ¬nh áº£nh"})

@app.route('/stats', methods=['GET'])
def get_stats():
    return jsonify({
        "total_images": len(image_paths),
        "device": device,
        "model": model_name,
        "image_folder": product_image_folder,
        "augmentation_enabled": augmentation_enabled
    })

@app.route('/toggle_augmentation', methods=['POST'])
def toggle_augmentation():
    global augmentation_enabled
    data = request.get_json()
    if 'enabled' in data:
        augmentation_enabled = data['enabled']
        logging.info(f"ÄÃ£ {('báº­t' if augmentation_enabled else 'táº¯t')} tÃ­nh nÄƒng tÄƒng cÆ°á»ng dá»¯ liá»‡u")
        return jsonify({"status": "success", "augmentation_enabled": augmentation_enabled})

    return jsonify({"error": "Invalid request"}), 400

if __name__ == '__main__':
    load_image_features()
    app.run(host='0.0.0.0', port=5000, debug=True)
